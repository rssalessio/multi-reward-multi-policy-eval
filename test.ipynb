{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoundResult(value=5.1823334656784485, w=array([[0.28083245, 0.06877288],\n",
      "       [0.        , 0.25322662],\n",
      "       [0.31439408, 0.08277397]]))\n",
      "BoundResult(value=5.182333482488856, w=array([[0.28083245, 0.06877288],\n",
      "       [0.        , 0.25322662],\n",
      "       [0.31439408, 0.08277397]]))\n",
      "BoundResult(value=5.182333480276443, w=array([[0.28083245, 0.06877288],\n",
      "       [0.        , 0.25322662],\n",
      "       [0.31439408, 0.08277397]]))\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cp\n",
    "import numpy as np\n",
    "import dccp\n",
    "import numpy.typing as npt\n",
    "from enum import Enum\n",
    "from multireward_ope.tabular.mdp import MDP\n",
    "from multireward_ope.tabular.characteristic_time import CharacteristicTimeSolver\n",
    "from multireward_ope.tabular.reward_set import RewardSet, RewardSetCircle, RewardSetType, RewardSetRewardFree, RewardSetBox\n",
    "from typing import NamedTuple\n",
    "\n",
    "\n",
    "mdp = MDP.generate_random_mdp(3, 2)\n",
    "policy = np.array([0, 1, 0], dtype=np.long)\n",
    "rewards = RewardSetCircle(mdp.dim_state, np.zeros(mdp.dim_state), radius=1, p=2)\n",
    "rbox = RewardSetBox(mdp.dim_state, np.zeros(mdp.dim_state), np.ones(mdp.dim_state))\n",
    "rfree = RewardSetRewardFree(mdp.dim_state)\n",
    "solver = CharacteristicTimeSolver(mdp.dim_state, mdp.dim_action)\n",
    "solver.build_problem(rewards)\n",
    "\n",
    "print(solver.solve(0.9, mdp, policy))\n",
    "\n",
    "solver.build_problem(rfree)\n",
    "print(solver.solve(0.9, mdp, policy))\n",
    "\n",
    "solver.build_problem(rbox)\n",
    "print(solver.solve(0.9, mdp, policy))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.07928891e-10 1.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00]]\n",
      "[[6.65545904e-10 9.99999999e-01]\n",
      " [0.00000000e+00 1.00000000e+00]\n",
      " [0.00000000e+00 1.00000000e+00]]\n",
      "[[0.         1.        ]\n",
      " [0.18933516 0.81066484]\n",
      " [0.         1.        ]\n",
      " [0.         1.        ]]\n",
      "[[0.         1.        ]\n",
      " [0.27796938 0.72203062]\n",
      " [0.11222818 0.88777182]\n",
      " [0.         1.        ]\n",
      " [0.         1.        ]]\n",
      "[[0.         1.        ]\n",
      " [0.22417685 0.77582315]\n",
      " [0.27065485 0.72934515]\n",
      " [0.0705685  0.9294315 ]\n",
      " [0.0017292  0.9982708 ]\n",
      " [0.         1.        ]]\n",
      "[[0.         1.        ]\n",
      " [0.21909058 0.78090942]\n",
      " [0.23245887 0.76754113]\n",
      " [0.14626051 0.85373949]\n",
      " [0.11233193 0.88766807]\n",
      " [0.0049633  0.9950367 ]\n",
      " [0.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from multireward_ope.tabular.envs.riverswim import RiverSwim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "results_circle = []\n",
    "results_rfree = []\n",
    "results_box = []\n",
    "np.random.seed(0)\n",
    "for s in range(2, 10):\n",
    "    mdp = RiverSwim(s)\n",
    "    policy = np.ones(mdp.dim_state, dtype=np.long)\n",
    "    rewards = RewardSetCircle(mdp.dim_state, np.zeros(mdp.dim_state), radius=1, p=2)\n",
    "    rbox = RewardSetBox(mdp.dim_state, np.zeros(mdp.dim_state), np.ones(mdp.dim_state))\n",
    "    rfree = RewardSetRewardFree(mdp.dim_state)\n",
    "    solver = CharacteristicTimeSolver(mdp.dim_state, mdp.dim_action)\n",
    "    solver.build_problem(rewards)\n",
    "    results_circle.append(solver.solve(0.9, mdp, policy).value)\n",
    "\n",
    "    solver.build_problem(rfree)\n",
    "    solution = solver.solve(0.9, mdp, policy)\n",
    "    # print(solution.w / solution.w.sum(-1, keepdims=True))\n",
    "    results_rfree.append(solution.value)\n",
    "\n",
    "    solver.build_problem(rbox)\n",
    "    results_box.append(solver.solve(0.9, mdp, policy).value)\n",
    "plt.plot(range(2,10), results_circle, label='$\\|r\\|_2 \\leq 1, r\\in [0,1]$')\n",
    "plt.plot(range(2,10), results_rfree, label='All rewards in [0,1] (closed-form)')\n",
    "plt.plot(range(2,11), results_box, label='All rewards in [0,1]')\n",
    "plt.legend()\n",
    "plt.xlabel('Num states')\n",
    "plt.ylabel('Characteristic time $T^\\star$')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
